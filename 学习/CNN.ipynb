{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danyang/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/danyang/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/danyang/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/danyang/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/danyang/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/danyang/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import sys ,os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf #只是用来加载mnist数据集\n",
    "from PIL import Image\n",
    "import pandas as pd \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_label(y):\n",
    "    one_hot_label = np.zeros((y.shape[0],10))\n",
    "    y = y.reshape(y.shape[0])\n",
    "    one_hot_label[range(y.shape[0]),y] = 1\n",
    "    return one_hot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n",
      "shape of x_train is :(60000, 1, 28, 28)\n",
      "shape of t_train is :(60000, 10)\n",
      "shape of x_test is :(10000, 1, 28, 28)\n",
      "shape of t_test is :(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# #（训练图像，训练标签），（测试图像，测试标签）\n",
    "# # mnist的图像均为28*28尺寸的数据，通道为1\n",
    "(x_train_origin,t_train_origin),(x_test_origin,t_test_origin) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = x_train_origin/255.0\n",
    "X_test = x_test_origin/255.0\n",
    "m,h,w = x_train_origin.shape\n",
    "X_train = X_train.reshape((m,1,h,w))\n",
    "y_train = one_hot_label(t_train_origin)\n",
    "\n",
    "m,h,w = x_test_origin.shape\n",
    "X_test = X_test.reshape((m,1,h,w))\n",
    "y_test = one_hot_label(t_test_origin)\n",
    "print(\"shape of x_train is :\"+repr(X_train.shape))\n",
    "print(\"shape of t_train is :\"+repr(y_train.shape))\n",
    "print(\"shape of x_test is :\"+repr(X_test.shape))\n",
    "print(\"shape of t_test is :\"+repr(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y is:5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 0\n",
    "plt.imshow(X_train[index].reshape((28,28)),cmap = plt.cm.gray)\n",
    "print(\"y is:\"+str(np.argmax(y_train[index])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col2(input_data,fh,fw,stride=1,pad=0):\n",
    "    '''\n",
    "     Arguments:\n",
    "     \n",
    "     input_data--输入数据，shape为(Number of example,Channel,Height,Width)\n",
    "     fh -- 滤波器的height\n",
    "     fw --滤波器的width\n",
    "     stride -- 步幅\n",
    "     pad -- 填充\n",
    "     \n",
    "     Returns :\n",
    "     col -- 输入数据根据滤波器、步幅等展开的二维数组，每一行代表一条卷积数据\n",
    "    '''\n",
    "    N,C,H,W = input_data.shape\n",
    "    \n",
    "    out_h = (H + 2*pad - fh)//stride+1\n",
    "    out_w = (W+2*pad-fw)//stride+1\n",
    "#     print(input_data)\n",
    "    img = np.pad(input_data,[(0,0),(0,0),(pad,pad),(pad,pad)],\"constant\")\n",
    "#     print('img',img)\n",
    "    col = np.zeros((N,out_h,out_w,fh*fw*C))\n",
    "    \n",
    "    #将所有维度上需要卷积的值展开成一列\n",
    "    for y in range(out_h):\n",
    "        y_start = y * stride\n",
    "        y_end =  y_start + fh\n",
    "        for x in range(out_w):\n",
    "            x_start = x*stride\n",
    "            x_end = x_start+fw\n",
    "            col[:,y,x] = img[:,:,y_start:y_end,x_start:x_end].reshape(N,-1)\n",
    "    col = col.reshape(N*out_h*out_w,-1)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1 1 1]\n",
      "   [3 2 2]\n",
      "   [3 4 3]]]]\n",
      "[[1. 1. 3. 2.]\n",
      " [1. 1. 2. 2.]\n",
      " [3. 2. 3. 4.]\n",
      " [2. 2. 4. 3.]]\n",
      "[[[[1. 1. 1.]\n",
      "   [3. 2. 2.]\n",
      "   [3. 4. 3.]]]]\n"
     ]
    }
   ],
   "source": [
    "a = np.random.randint(0,5,size=(1,1,3,3))\n",
    "print(a)\n",
    "\n",
    "c = im2col2(a,2,2,1,0)\n",
    "print(c)\n",
    "d = col2im2(c,out_shape=(1,1,3,3),fh=2,fw=2,stride=1)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col2im2(col,out_shape,fh,fw,stride=1,pad=0):\n",
    "    '''\n",
    "     Arguments:\n",
    "     col: 二维数组     \n",
    "     out_shape-- 输出的shape，shape为(Number of example,Channel,Height,Width)\n",
    "     fh -- 滤波器的height\n",
    "     fw --滤波器的width\n",
    "     stride -- 步幅\n",
    "     pad -- 填充\n",
    "     \n",
    "     Returns :\n",
    "     img -- 将col转换成的img ，shape为out_shape\n",
    "    '''\n",
    "    N,C,H,W = out_shape\n",
    "    \n",
    "    col_m,col_n = col.shape\n",
    "    \n",
    "    out_h = (H + 2*pad - fh)//stride+1\n",
    "    out_w = (W+2*pad-fw)//stride+1\n",
    "\n",
    "    \n",
    "\n",
    "    img = np.zeros((N, C, H , W))\n",
    "   # img = np.pad(img,[(0,0),(0,0),(pad,pad),(pad,pad)],\"constant\")\n",
    "\n",
    "    #将col转换成一个filter\n",
    "    for c in range(C):\n",
    "        for y in range(out_h):\n",
    "            for x in range(out_w):\n",
    "                col_index = (c*out_h*out_w)+y*out_w+x\n",
    "                ih = y*stride\n",
    "                iw =  x*stride\n",
    "                img[:,c,ih:ih+fh,iw:iw+fw] = col[col_index].reshape((fh,fw))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col2test():\n",
    "    a = np.random.randint(0,5,size=(2,3,4,4))\n",
    "    c = im2col2(a,2,2,2,1)\n",
    "\n",
    "    a = np.random.randint(0,5,size=(1,1,3,3))\n",
    "    print(a)\n",
    "    \n",
    "    c = im2col2(a,2,2,1,0)\n",
    "    print(c)\n",
    "    d = col2im2(c,out_shape=(1,1,3,3),fh=2,fw=2,stride=1)\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[2 1 3]\n",
      "   [4 4 2]\n",
      "   [2 1 4]]]]\n",
      "[[2. 1. 4. 4.]\n",
      " [1. 3. 4. 2.]\n",
      " [4. 4. 2. 1.]\n",
      " [4. 2. 1. 4.]]\n",
      "[[[[2. 1. 3.]\n",
      "   [4. 4. 2.]\n",
      "   [2. 1. 4.]]]]\n"
     ]
    }
   ],
   "source": [
    "im2col2test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1, 4, 0, 2],\n",
       "         [4, 0, 0, 1],\n",
       "         [3, 4, 4, 2],\n",
       "         [4, 4, 0, 0]],\n",
       "\n",
       "        [[1, 0, 1, 0],\n",
       "         [4, 0, 4, 4],\n",
       "         [4, 4, 4, 4],\n",
       "         [2, 2, 0, 4]],\n",
       "\n",
       "        [[3, 2, 0, 2],\n",
       "         [3, 1, 3, 0],\n",
       "         [4, 3, 0, 1],\n",
       "         [2, 1, 3, 4]]],\n",
       "\n",
       "\n",
       "       [[[1, 0, 1, 2],\n",
       "         [2, 3, 1, 3],\n",
       "         [3, 4, 0, 3],\n",
       "         [4, 3, 4, 1]],\n",
       "\n",
       "        [[1, 2, 4, 4],\n",
       "         [2, 4, 0, 2],\n",
       "         [3, 0, 0, 2],\n",
       "         [1, 0, 4, 2]],\n",
       "\n",
       "        [[1, 2, 0, 0],\n",
       "         [3, 3, 3, 4],\n",
       "         [2, 2, 4, 2],\n",
       "         [2, 0, 1, 4]]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.randint(0,5,size=(2,3,4,4))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 4., 4., 0., 1., 0., 4., 0., 3., 2., 3., 1.],\n",
       "       [4., 0., 0., 0., 0., 1., 0., 4., 2., 0., 1., 3.],\n",
       "       [0., 2., 0., 1., 1., 0., 4., 4., 0., 2., 3., 0.],\n",
       "       [4., 0., 3., 4., 4., 0., 4., 4., 3., 1., 4., 3.],\n",
       "       [0., 0., 4., 4., 0., 4., 4., 4., 1., 3., 3., 0.],\n",
       "       [0., 1., 4., 2., 4., 4., 4., 4., 3., 0., 0., 1.],\n",
       "       [3., 4., 4., 4., 4., 4., 2., 2., 4., 3., 2., 1.],\n",
       "       [4., 4., 4., 0., 4., 4., 2., 0., 3., 0., 1., 3.],\n",
       "       [4., 2., 0., 0., 4., 4., 0., 4., 0., 1., 3., 4.],\n",
       "       [1., 0., 2., 3., 1., 2., 2., 4., 1., 2., 3., 3.],\n",
       "       [0., 1., 3., 1., 2., 4., 4., 0., 2., 0., 3., 3.],\n",
       "       [1., 2., 1., 3., 4., 4., 0., 2., 0., 0., 3., 4.],\n",
       "       [2., 3., 3., 4., 2., 4., 3., 0., 3., 3., 2., 2.],\n",
       "       [3., 1., 4., 0., 4., 0., 0., 0., 3., 3., 2., 4.],\n",
       "       [1., 3., 0., 3., 0., 2., 0., 2., 3., 4., 4., 2.],\n",
       "       [3., 4., 4., 3., 3., 0., 1., 0., 2., 2., 2., 0.],\n",
       "       [4., 0., 3., 4., 0., 0., 0., 4., 2., 4., 0., 1.],\n",
       "       [0., 3., 4., 1., 0., 2., 4., 2., 4., 2., 1., 4.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = im2col2(a,2,2,1,0)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 12 into shape (2,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-07f94833555b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol2im2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-3f0bf7975ea0>\u001b[0m in \u001b[0;36mcol2im2\u001b[0;34m(col, out_shape, fh, fw, stride, pad)\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mih\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0miw\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mih\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mih\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0miw\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 12 into shape (2,2)"
     ]
    }
   ],
   "source": [
    "d = col2im2(c,out_shape=(2,3,4,4),fh=2,fw=2,stride=1)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(input_X):\n",
    "    A = np.where(input_X < 0, 0, input_X)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(input_X):\n",
    "    exp_a = np.exp(input_X)\n",
    "    sum_exp_a = np.sum(exp_a, axis=1)\n",
    "    sum_exp_a = sum_exp_a.reshape(input_X.shape[0],-1)\n",
    "    ret = exp_a/sum_exp_a\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(labels, logits):\n",
    "    return -np.sum(labels*np.log(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution:\n",
    "    def __init__(self, W, fb, stride = 1, pad = 0):\n",
    "        \"\"\"\n",
    "        W-- 滤波器权重，shape为(FN,NC,FH,FW),FN 为滤波器的个数\n",
    "        fb -- 滤波器的偏置，shape 为(1,FN) \n",
    "        stride -- 步长\n",
    "        pad -- 填充个数\n",
    "        \"\"\"\n",
    "        self.W = W\n",
    "        self.fb = fb\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        self.col_X = None\n",
    "        self.X = None\n",
    "        self.col_W = None\n",
    "        \n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "        self.out_shape = None\n",
    "        \n",
    "    def forward(self, input_X):\n",
    "        \"\"\"\n",
    "        input_X-- shape为(m,nc,height,width)\n",
    "        \"\"\"  \n",
    "        self.X = input_X\n",
    "        FN, NC, FH, FW = self.W.shape\n",
    "        m, input_nc, input_h, input_w = self.X.shape\n",
    "\n",
    "        out_h = int((input_h + 2*self.pad - FH)/self.stride + 1)\n",
    "        out_w = int((input_w + 2*self.pad - FW)/self.stride + 1)\n",
    "#         print('===================Convolution======================')\n",
    "#         print(\"input_X\",input_X)\n",
    "#         print(input_X.shape)\n",
    "        #将输入数据展开成二维数组，shape为（m*out_h*out_w,FH*FW*C)\n",
    "        self.col_X = col_X = im2col2(self.X,FH,FW,self.stride,self.pad)\n",
    "#         print(\"self.col_X\",self.col_X)\n",
    "#         print(self.col_X.shape)\n",
    "        #将滤波器一个个按列展开(FH*FW*C,FN)\n",
    "        self.col_W = col_W = self.W.reshape(FN,-1).T\n",
    "#         print('self.col_W',self.col_W)\n",
    "#         print(self.col_W.shape)\n",
    "        out = np.dot(col_X,col_W)+self.fb\n",
    "#         print('out',out)\n",
    "#         print(out.shape)\n",
    "        out = out.T\n",
    "#         print(out.shape)\n",
    "        out = out.reshape(m,FN,out_h,out_w)\n",
    "#         print(out.shape)\n",
    "\n",
    "        self.out_shape = out.shape\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dz, learning_rate):\n",
    "#         print('dz',dz)\n",
    "        print(dz.shape)\n",
    "        assert(dz.shape == self.out_shape)\n",
    "        \n",
    "        FN, NC, FH, FW = self.W.shape\n",
    "        o_FN,o_NC,o_FH,o_FW = self.out_shape\n",
    "        \n",
    "        col_dz = dz.reshape(o_NC, -1)\n",
    "        col_dz = col_dz.T\n",
    "        print('col_dz',col_dz.shape)\n",
    "        print('self.col_X',self.col_X.shape)\n",
    "        self.dW = np.dot(self.col_X.T,col_dz)  #shape is (FH*FW*C,FN)\n",
    "        self.db = np.sum(col_dz,axis=0,keepdims=True)\n",
    "\n",
    "        self.dW = self.dW.T.reshape(self.W.shape)\n",
    "        self.db = self.db.reshape(self.fb.shape)\n",
    "        \n",
    "        d_col_x = np.dot(col_dz,self.col_W.T) #shape is (m*out_h*out_w,FH,FW*C)\n",
    "        print('d_col_x',d_col_x.shape)\n",
    "        dx = col2im2(d_col_x,self.X.shape,FH,FW,stride=1)\n",
    "        print('dx',dx.shape)\n",
    "        \n",
    "        assert(dx.shape == self.X.shape)\n",
    "        #更新W和b\n",
    "        self.W = self.W - learning_rate*self.dW\n",
    "        self.fb = self.fb -learning_rate*self.db\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride = 1, pad = 0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad \n",
    "        self.X = None\n",
    "        self.arg_max = None\n",
    "        \n",
    "    def forward (self, input_X):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        input_X-- shape为(m,nc,height,width)\n",
    "        \"\"\" \n",
    "        self.X = input_X\n",
    "        N , C, H, W = input_X.shape\n",
    "        out_h = int(1+(H-self.pool_h)/self.stride)\n",
    "        out_w = int(1+(W-self.pool_w)/self.stride)\n",
    "        #展开\n",
    "#         print('input_X',input_X.shape)\n",
    "        col = im2col2(input_X,self.pool_h,self.pool_w,self.stride,self.pad)\n",
    "#         print('col',col.shape)\n",
    "        col = col.reshape(-1,self.pool_h*self.pool_w)\n",
    "#         print('col',col.shape)\n",
    "\n",
    "        arg_max = np.argmax(col,axis=1)\n",
    "#         print('arg_max',arg_max.shape)\n",
    "        #最大值\n",
    "        out = np.max(col,axis=1)\n",
    "#         print('out',out.shape)\n",
    "        out =out.T.reshape(N,C,out_h,out_w)\n",
    "#         print('out',out.shape)\n",
    "        self.arg_max = arg_max\n",
    "        return out\n",
    "        \n",
    "    def backward(self ,dz):\n",
    "        \"\"\"\n",
    "        反向传播\n",
    "        Arguments:\n",
    "        dz-- out的导数，shape与out 一致\n",
    "        \n",
    "        Return:\n",
    "        返回前向传播是的input_X的导数\n",
    "        \"\"\" \n",
    "        pool_size = self.pool_h*self.pool_w\n",
    "        dmax = np.zeros((dz.size,pool_size))\n",
    "        dmax[np.arange(self.arg_max.size),self.arg_max.flatten()] = dz.flatten()\n",
    "        \n",
    "        dx = col2im2(dmax,out_shape=self.X.shape,fh=self.pool_h,fw=self.pool_w,stride=self.stride)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self ,X):\n",
    "        self.mask = X <= 0\n",
    "        out = X\n",
    "        out[self.mask] = 0\n",
    "        return out\n",
    "    \n",
    "    def backward(self,dz):\n",
    "        dz[self.mask] = 0\n",
    "        dx = dz \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftMax:\n",
    "    def __init__ (self):\n",
    "        self.y_hat = None\n",
    "        \n",
    "    def forward(self,X):\n",
    "        \n",
    "        self.y_hat = softmax(X)\n",
    "        return self.y_hat\n",
    "    \n",
    "    def backward(self,labels):\n",
    "        m = labels.shape[0]\n",
    "        dx = (self.y_hat - labels)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(logits,label):\n",
    "    return cross_entropy_error(label,logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self,W,b):\n",
    "        self.W = W # shape is (n_x,n_unit)\n",
    "        self.b  = b  # shape is(1,n_unit)\n",
    "        self.X = None\n",
    "        self.origin_x_shape = None\n",
    "        \n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "        \n",
    "        self.out_shape =None\n",
    "    def forward(self,X):\n",
    "        self.origin_x_shape = X.shape \n",
    "        self.X = X.reshape(X.shape[0],-1)#(m,n)\n",
    "        out =  np.dot(self.X, self.W)+self.b\n",
    "        self.out_shape = out.shape\n",
    "        return out\n",
    "    \n",
    "    def backward(self,dz,learning_rate):\n",
    "        \"\"\"\n",
    "        dz-- 前面的导数\n",
    "        \"\"\"  \n",
    "#         print(\"Affine backward\")\n",
    "#         print(self.X.shape)\n",
    "#         print(dz.shape)\n",
    "#         print(self.W.shape)\n",
    "    \n",
    "        assert(dz.shape == self.out_shape)\n",
    "        \n",
    "        m = self.X.shape[0]\n",
    "        \n",
    "        self.dW = np.dot(self.X.T,dz)/m\n",
    "        self.db = np.sum(dz,axis=0,keepdims=True)/m\n",
    "        \n",
    "        assert(self.dW.shape == self.W.shape)\n",
    "        assert(self.db.shape == self.b.shape)\n",
    "        \n",
    "        dx = np.dot(dz,self.W.T)\n",
    "        assert(dx.shape == self.X.shape)\n",
    "        \n",
    "        dx = dx.reshape(self.origin_x_shape) # 保持与之前的x一样的shape\n",
    "        \n",
    "        #更新W和b\n",
    "        self.W = self.W-learning_rate*self.dW\n",
    "        self.b = self.b - learning_rate*self.db\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConvNet:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.X = None\n",
    "        self.Y= None\n",
    "        self.layers = []\n",
    "\n",
    "    def add_conv_layer(self,n_filter,n_c , f, stride=1, pad=0):\n",
    "        \"\"\"\n",
    "        添加一层卷积层\n",
    "        Arguments:\n",
    "        n_c -- 输入数据通道数，也即卷积层的通道数\n",
    "        n_filter -- 滤波器的个数\n",
    "        f --滤波器的长/宽\n",
    "\n",
    "        Return :\n",
    "        Conv -- 卷积层\n",
    "        \"\"\"\n",
    "\n",
    "        # 初始化W，b\n",
    "        W = np.random.randn(n_filter, n_c, f, f)*0.01\n",
    "        fb = np.zeros((1, n_filter))\n",
    "        # 卷积层\n",
    "        Conv = Convolution(W, fb, stride=stride, pad=pad)\n",
    "        return Conv\n",
    "\n",
    "    def add_maxpool_layer(self, pool_shape, stride=1, pad=0):\n",
    "        \"\"\"\n",
    "        添加一层池化层\n",
    "        Arguments:\n",
    "        pool_shape -- 滤波器的shape\n",
    "        f -- 滤波器大小\n",
    "        Return :\n",
    "         Pool -- 初始化的Pool类\n",
    "        \"\"\"\n",
    "        pool_h, pool_w = pool_shape\n",
    "        pool = Pooling(pool_h, pool_w, stride=stride, pad=pad)\n",
    "        \n",
    "        return pool\n",
    "    \n",
    "    def add_affine(self,n_x, n_units):\n",
    "        \"\"\"\n",
    "        添加一层全连接层\n",
    "        Arguments:\n",
    "        n_x -- 输入个数\n",
    "        n_units -- 神经元个数\n",
    "        Return :\n",
    "        fc_layer -- Affine层对象\n",
    "        \"\"\"\n",
    "        \n",
    "        W= np.random.randn(n_x, n_units)*0.01\n",
    "        \n",
    "        b = np.zeros((1, n_units))\n",
    "        \n",
    "        fc_layer = Affine(W,b)\n",
    "        \n",
    "        return fc_layer\n",
    "    \n",
    "    def add_relu(self):\n",
    "        relu_layer =  Relu()\n",
    "        return relu_layer\n",
    "    \n",
    "    \n",
    "    def add_softmax(self):\n",
    "        softmax_layer = SoftMax()\n",
    "        return softmax_layer\n",
    "    \n",
    "    #计算卷积或池化后的H和W\n",
    "    def cacl_out_hw(self,HW,f,stride = 1,pad = 0):\n",
    "        return (HW+2*pad - f)/stride+1\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    def init_model(self,train_X,n_classes):\n",
    "        \"\"\"\n",
    "        初始化一个卷积层网络\n",
    "        \"\"\"\n",
    "        N,C,H,W = train_X.shape\n",
    "        #卷积层\n",
    "        n_filter = 4\n",
    "        f = 7\n",
    "        \n",
    "        conv_layer = self.add_conv_layer(n_filter= n_filter,n_c=C,f=f,stride=1)\n",
    "        \n",
    "        out_h = self.cacl_out_hw(H,f)\n",
    "        out_w = self.cacl_out_hw(W,f)\n",
    "        out_ch = n_filter\n",
    "        \n",
    "        self.layers.append(conv_layer)\n",
    "        \n",
    "        #Relu\n",
    "        relu_layer = self.add_relu()\n",
    "        self.layers.append(relu_layer)\n",
    "        \n",
    "        #池化\n",
    "        f = 2\n",
    "        pool_layer = self.add_maxpool_layer(pool_shape=(f,f),stride=2)\n",
    "        out_h = self.cacl_out_hw(out_h,f,stride=2)\n",
    "        out_w = self.cacl_out_hw(out_w,f,stride=2)\n",
    "        #out_ch 不改变\n",
    "        self.layers.append(pool_layer)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        #Affine层\n",
    "        n_x = int(out_h*out_w*out_ch)\n",
    "        n_units = 32\n",
    "        fc_layer = self.add_affine(n_x=n_x,n_units=n_units)\n",
    "        self.layers.append(fc_layer)\n",
    "        \n",
    "        #Relu\n",
    "        relu_layer = self.add_relu()\n",
    "        self.layers.append(relu_layer)\n",
    "        \n",
    "        #Affine\n",
    "        fc_layer = self.add_affine(n_x=n_units,n_units=n_classes)\n",
    "        self.layers.append(fc_layer)\n",
    "        \n",
    "        #SoftMax\n",
    "        softmax_layer = self.add_softmax()\n",
    "        self.layers.append(softmax_layer)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward_progation(self,train_X, print_out = False):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        Arguments:\n",
    "        train_X -- 训练数据\n",
    "        f -- 滤波器大小\n",
    "\n",
    "        Return :\n",
    "         Z-- 前向传播的结果\n",
    "         loss -- 损失值\n",
    "        \"\"\"\n",
    "    \n",
    "        \n",
    "        N,C,H,W = train_X.shape\n",
    "        index = 0\n",
    "        # 卷积层\n",
    "        conv_layer = self.layers[index]\n",
    "        X = conv_layer.forward(train_X)\n",
    "        index =index+1\n",
    "        if print_out:\n",
    "            print(\"卷积之后：\"+str(X.shape))\n",
    "        # Relu\n",
    "        relu_layer =  self.layers[index]\n",
    "        index =index+1\n",
    "        X = relu_layer.forward(X)\n",
    "        if print_out:\n",
    "            print(\"Relu：\"+str(X.shape))\n",
    "            \n",
    "        \n",
    "        # 池化层\n",
    "        pool_layer = self.layers[index]\n",
    "        index =index+1\n",
    "        X = pool_layer.forward(X)\n",
    "        if print_out:\n",
    "            print(\"池化：\"+str(X.shape))\n",
    "\n",
    "\n",
    "        #Affine层\n",
    "        fc_layer = self.layers[index]\n",
    "        index =index+1\n",
    "        X = fc_layer.forward(X)\n",
    "        if print_out:\n",
    "            print(\"Affline 层的X：\"+str(X.shape))\n",
    "\n",
    "        #Relu\n",
    "        relu_layer = self.layers[index]\n",
    "        index =index+1\n",
    "        X = relu_layer.forward(X)\n",
    "        if print_out:\n",
    "            print(\"Relu 层的X：\"+str(X.shape))\n",
    "        \n",
    "        #Affine层\n",
    "        fc_layer = self.layers[index]\n",
    "        index =index+1\n",
    "        X = fc_layer.forward(X)\n",
    "        if print_out:\n",
    "            print(\"Affline 层的X：\"+str(X.shape))\n",
    "\n",
    "        #SoftMax层\n",
    "        sofmax_layer = self.layers[index]\n",
    "        index =index+1\n",
    "        A = sofmax_layer.forward(X)\n",
    "        if print_out:\n",
    "            print(\"Softmax 层的X：\"+str(A.shape))\n",
    "            \n",
    "        return A\n",
    "        \n",
    "    def back_progation(self,train_y,learning_rate):\n",
    "        \"\"\"\n",
    "        反向传播\n",
    "        Arguments:\n",
    "   \n",
    "        \"\"\"\n",
    "        index = len(self.layers)-1\n",
    "        sofmax_layer = self.layers[index]\n",
    "        index -= 1\n",
    "        dz = sofmax_layer.backward(train_y)\n",
    "        \n",
    "        fc_layer = self.layers[index]\n",
    "        dz = fc_layer.backward(dz,learning_rate=learning_rate)\n",
    "        index -= 1\n",
    "        \n",
    "        relu_layer = self.layers[index]\n",
    "        dz = relu_layer.backward(dz)\n",
    "        index -= 1\n",
    "        \n",
    "        fc_layer = self.layers[index]\n",
    "        dz = fc_layer.backward(dz,learning_rate=learning_rate)\n",
    "        index -= 1\n",
    "        \n",
    "        pool_layer = self.layers[index]\n",
    "        dz = pool_layer.backward(dz)\n",
    "        index -= 1\n",
    "        \n",
    "        relu_layer =  self.layers[index]\n",
    "        dz = relu_layer.backward(dz)\n",
    "        index -= 1\n",
    "        \n",
    "        conv_layer = self.layers[index]\n",
    "        conv_layer.backward(dz,learning_rate=learning_rate)\n",
    "        index -= 1\n",
    "        \n",
    "      \n",
    "    def get_minibatch(self,batch_data,minibatch_size,num):\n",
    "        m_examples = batch_data.shape[0]\n",
    "        minibatches = math.ceil( m_examples / minibatch_size)\n",
    " \n",
    "        if(num < minibatches):\n",
    "            return batch_data[num*minibatch_size:(num+1)*minibatch_size]\n",
    "        else:\n",
    "            return batch_data[num*minibatch_size:m_examples]\n",
    "    \n",
    "    \n",
    "    def optimize(self,train_X, train_y,minibatch_size,learning_rate=0.05,num_iters=500):\n",
    "        \"\"\"\n",
    "        优化方法\n",
    "        Arguments:\n",
    "        train_X -- 训练数据 \n",
    "        train_y -- 训练数据的标签\n",
    "        learning_rate -- 学习率\n",
    "        num_iters -- 迭代次数\n",
    "        minibatch_size \n",
    "        \"\"\"\n",
    "        m = train_X.shape[0]\n",
    "        num_batches  = math.ceil(m / minibatch_size)\n",
    "        \n",
    "        costs = []\n",
    "        for iteration in range(num_iters):\n",
    "            iter_cost = 0\n",
    "            for batch_num in range(num_batches):\n",
    "                minibatch_X = self.get_minibatch(train_X,minibatch_size,batch_num)\n",
    "                minibatch_y = self.get_minibatch(train_y,minibatch_size,batch_num)\n",
    "                \n",
    "                # 前向传播\n",
    "                A = self.forward_progation(minibatch_X,print_out=False)\n",
    "                #损失:\n",
    "                cost = compute_cost (A,minibatch_y)\n",
    "                #反向传播\n",
    "                self.back_progation(minibatch_y,learning_rate)\n",
    "                if(iteration%100 == 0):\n",
    "                    iter_cost += cost/num_batches\n",
    "                    \n",
    "#             if(iteration%100 == 0):\n",
    "            print(\"After %d iters ,cost is :%g\" %(iteration,iter_cost))\n",
    "            costs.append(iter_cost)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        #画出损失函数图\n",
    "        plt.plot(costs)\n",
    "        plt.xlabel(\"iterations/hundreds\")\n",
    "        plt.ylabel(\"costs\")\n",
    "        plt.show()\n",
    "        \n",
    "       \n",
    "    def predicate(self, train_X):\n",
    "        \"\"\"\n",
    "        预测\n",
    "        \"\"\"\n",
    "        logits = self.forward_progation(train_X)\n",
    "        one_hot = np.zeros_like(logits)\n",
    "        one_hot[range(train_X.shape[0]),np.argmax(logits,axis=1)] = 1\n",
    "        return one_hot   \n",
    "\n",
    "    def fit(self,train_X, train_y):\n",
    "        \"\"\"\n",
    "        训练\n",
    "        \"\"\"\n",
    "        self.X = train_X\n",
    "        self.Y = train_y\n",
    "        n_y = train_y.shape[1]\n",
    "        m = train_X.shape[0]\n",
    "        \n",
    "        #初始化模型\n",
    "        self.init_model(train_X,n_classes=n_y)\n",
    "\n",
    "        self.optimize(train_X, train_y,minibatch_size=10,learning_rate=0.05,num_iters=1)\n",
    "        \n",
    "        logits = self.predicate(train_X)\n",
    "        \n",
    "        accuracy = np.sum(np.argmax(logits,axis=1) == np.argmax(train_y,axis=1))/m\n",
    "        print(\"训练集的准确率为：%g\" %(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 4, 22, 22)\n",
      "col_dz (4840, 4)\n",
      "self.col_X (4840, 49)\n",
      "d_col_x (4840, 49)\n",
      "dx (10, 1, 28, 28)\n",
      "After 0 iters ,cost is :23.0253\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集的准确率为：0.3\n"
     ]
    }
   ],
   "source": [
    "convNet = SimpleConvNet()\n",
    "#拿20张先做实验\n",
    "train_X = X_train[0:10]\n",
    "train_y = y_train[0:10]\n",
    "convNet.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1, 28, 28)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from activators import ReluActivator, IdentityActivator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patch(input_array, i, j, filter_width, filter_height, stride):\n",
    "    '''\n",
    "    从输入数组中获取本次卷积的区域，\n",
    "    自动适配输入为2D和3D的情况\n",
    "    '''\n",
    "    start_i = i * stride\n",
    "    start_j = j * stride\n",
    "    if input_array.ndim == 2:\n",
    "        input_array_conv = input_array[start_i : start_i + filter_height, start_j : start_j + filter_width]\n",
    "        return input_array_conv\n",
    "    elif input_array.ndim == 3:\n",
    "        input_array_conv = input_array[:,\n",
    "            start_i : start_i + filter_height,\n",
    "            start_j : start_j + filter_width]\n",
    "        return input_array_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_index(array):\n",
    "    # 获取一个2D区域的最大值所在的索引\n",
    "    max_i = 0\n",
    "    max_j = 0\n",
    "    max_value = array[0, 0]\n",
    "    for i in range(array.shape[0]):\n",
    "        for j in range(array.shape[1]):\n",
    "            if array[i, j] > max_value:\n",
    "                max_value = array[i,j]\n",
    "                max_i, max_j = i, j\n",
    "    return max_i, max_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(input_array, kernel_array, output_array, stride, bias):\n",
    "    '''\n",
    "    计算卷积，自动适配输入为2D和3D的情况\n",
    "    '''\n",
    "    channel_number = input_array.ndim\n",
    "    output_width = output_array.shape[1]\n",
    "    output_height = output_array.shape[0]\n",
    "    kernel_width = kernel_array.shape[-1]\n",
    "    kernel_height = kernel_array.shape[-2]\n",
    "    for i in range(output_height):\n",
    "        for j in range(output_width):\n",
    "            output_array[i][j] = (    \n",
    "                get_patch(input_array, i, j, kernel_width, \n",
    "                    kernel_height, stride) * kernel_array\n",
    "                ).sum() + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(input_array, zp):\n",
    "    '''\n",
    "    为数组增加Zero padding，自动适配输入为2D和3D的情况\n",
    "    '''\n",
    "    if zp == 0:\n",
    "        return input_array\n",
    "    else:\n",
    "        if input_array.ndim == 3:\n",
    "            input_width = input_array.shape[2]\n",
    "            input_height = input_array.shape[1]\n",
    "            input_depth = input_array.shape[0]\n",
    "            padded_array = np.zeros((input_depth, input_height +2 * zp, input_width + 2 * zp))\n",
    "            padded_array[:, zp : zp + input_height, zp : zp + input_width] = input_array\n",
    "            return padded_array\n",
    "        elif input_array.ndim == 2:\n",
    "            input_width = input_array.shape[1]\n",
    "            input_height = input_array.shape[0]\n",
    "            padded_array = np.zeros((\n",
    "                input_height + 2 * zp,\n",
    "                input_width + 2 * zp))\n",
    "            padded_array[zp : zp + input_height,\n",
    "                zp : zp + input_width] = input_array\n",
    "            return padded_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def element_wise_op(array, op):\n",
    "    for i in np.nditer(array, op_flags=['readwrite']):\n",
    "        i[...] = op(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Filter(object):\n",
    "    def __init__(self, width, height, depth):\n",
    "        self.weights = np.random.uniform(-1e-4, 1e-4,(depth, height, width))\n",
    "        self.bias = 0\n",
    "        self.weights_grad = np.zeros(self.weights.shape)\n",
    "        self.bias_grad = 0\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'filter weights:\\n%s\\nbias:\\n%s' % (\n",
    "            repr(self.weights), repr(self.bias))\n",
    "    \n",
    "    def get_weights(self):\n",
    "        return self.weights\n",
    "    \n",
    "    def get_bias(self):\n",
    "        return self.bias\n",
    "    \n",
    "    def update(self, learning_rate):\n",
    "        self.weights -= learning_rate * self.weights_grad\n",
    "        self.bias -= learning_rate * self.bias_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(object):\n",
    "    '''\n",
    "    参数含义：\n",
    "    input_width:输入图片尺寸——宽度\n",
    "    input_height:输入图片尺寸——长度\n",
    "    channel_number:通道数，彩色为3，灰色为1\n",
    "    filter_width:卷积核的宽\n",
    "    filter_height:卷积核的长\n",
    "    filter_number:卷积核数量\n",
    "    zero_padding：补零长度\n",
    "    stride:步长\n",
    "    activator:激活函数\n",
    "    learning_rate:学习率\n",
    "    '''\n",
    "    def __init__(self, input_width, input_height,\n",
    "                 channel_number, filter_width,\n",
    "                 filter_height, filter_number,\n",
    "                 zero_padding, stride, activator,\n",
    "                 learning_rate):\n",
    "        self.input_width = input_width\n",
    "        self.input_height = input_height\n",
    "        self.channel_number = channel_number\n",
    "        self.filter_width = filter_width\n",
    "        self.filter_height = filter_height\n",
    "        self.filter_number = filter_number\n",
    "        self.zero_padding = zero_padding\n",
    "        self.stride = stride\n",
    "        self.output_width = \\\n",
    "            ConvLayer.calculate_output_size(\n",
    "            self.input_width, filter_width, zero_padding,\n",
    "            stride)\n",
    "        self.output_height = \\\n",
    "            ConvLayer.calculate_output_size(\n",
    "            self.input_height, filter_height, zero_padding,\n",
    "            stride)\n",
    "        self.output_array = np.zeros((self.filter_number,\n",
    "            self.output_height, self.output_width))\n",
    "        self.filters = []\n",
    "        for i in range(filter_number):\n",
    "            self.filters.append(Filter(filter_width,\n",
    "                filter_height, self.channel_number))\n",
    "        self.activator = activator\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def calculate_output_size(input_size, filter_size, zero_padding, stride):\n",
    "        return (input_size + 2*zero_padding - filter_size) // stride + 1\n",
    "    \n",
    "    def forward(self, input_array):\n",
    "        '''\n",
    "        计算卷积层的输出\n",
    "        输出结果保存在self.output_array\n",
    "        '''\n",
    "        self.input_array = input_array\n",
    "        self.padded_input_array = padding(input_array,self.zero_padding)\n",
    "        \n",
    "        for f in range(self.filter_number):\n",
    "            filter = self.filters[f]\n",
    "            conv(self.padded_input_array, filter.get_weights(), self.output_array[f], self.stride, filter.get_bias())\n",
    "        element_wise_op(self.output_array, \n",
    "                        self.activator.forward)\n",
    "        \n",
    "    def backward(self, input_array, sensitivity_array, activator):\n",
    "        '''\n",
    "        计算传递给前一层的误差项，以及计算每个权重的梯度\n",
    "        前一层的误差项保存在self.delta_array\n",
    "        梯度保存在Filter对象的weights_grad\n",
    "        '''\n",
    "        self.forward(input_array)\n",
    "        self.bp_sensitivity_map(sensitivity_array, activator)\n",
    "        self.bp_gradient(sensitivity_array)\n",
    "        \n",
    "    def update(self):\n",
    "        '''\n",
    "        按照梯度下降，更新权重\n",
    "        '''\n",
    "        for filter in self.filters:\n",
    "            filter.update(self.learning_rate)\n",
    "\n",
    "    def bp_sensitivity_map(self, sensitivity_array,\n",
    "                           activator):\n",
    "        '''\n",
    "        计算传递到上一层的sensitivity map\n",
    "        sensitivity_array: 本层的sensitivity map\n",
    "        activator: 上一层的激活函数\n",
    "        '''\n",
    "        # 处理卷积步长，对原始sensitivity map进行扩展\n",
    "        expanded_array = self.expand_sensitivity_map(\n",
    "            sensitivity_array)\n",
    "        # full卷积，对sensitivitiy map进行zero padding\n",
    "        # 虽然原始输入的zero padding单元也会获得残差\n",
    "        # 但这个残差不需要继续向上传递，因此就不计算了\n",
    "        expanded_width = expanded_array.shape[2]\n",
    "        zp = (self.input_width +  \n",
    "              self.filter_width - 1 - expanded_width) // 2\n",
    "        padded_array = padding(expanded_array, zp)\n",
    "        print('=======================padded_array========================')\n",
    "        print(padded_array)\n",
    "        # 初始化delta_array，用于保存传递到上一层的\n",
    "        # sensitivity map\n",
    "        self.delta_array = self.create_delta_array()\n",
    "        # 对于具有多个filter的卷积层来说，最终传递到上一层的\n",
    "        # sensitivity map相当于所有的filter的\n",
    "        # sensitivity map之和\n",
    "        \n",
    "        for f in range(self.filter_number):\n",
    "            #print('f',f)\n",
    "            filter = self.filters[f]\n",
    "            # 将filter权重翻转180度\n",
    "            flipped_weights = np.array(list(map(\n",
    "                lambda i: np.rot90(i, 2), \n",
    "                filter.get_weights())))\n",
    "\n",
    "#             flipped_weights = self.flip180(filter.get_weights())\n",
    "            # 计算与一个filter对应的delta_array\n",
    "            delta_array = self.create_delta_array()\n",
    "            #print('padded_array[f]',padded_array[f])\n",
    "            for d in range(delta_array.shape[0]):\n",
    "                conv(padded_array[f], flipped_weights[d],\n",
    "                    delta_array[d], 1, 0)\n",
    "            self.delta_array += delta_array\n",
    "        # 将计算结果与激活函数的偏导数做element-wise乘法操作\n",
    "        derivative_array = np.array(self.input_array)\n",
    "        element_wise_op(derivative_array, \n",
    "                        activator.backward)\n",
    "        self.delta_array *= derivative_array\n",
    "    \n",
    "    def bp_gradient(self,sensitivity_array):\n",
    "        # 处理卷积步长，对原始sensitivity map进行扩展\n",
    "        expanded_array = self.expand_sensitivity_map(sensitivity_array)\n",
    "        for f in range(self.filter_number):\n",
    "            filter = self.filters[f]\n",
    "            for d in range(filter.weights.shape[0]):\n",
    "                conv(self.padded_input_array[d], expanded_array[f], filter.weights_grad[d], 1, 0)\n",
    "            filter.bias_grad = expanded_array[f].sum()\n",
    "    \n",
    "    \n",
    "    def expand_sensitivity_map(self, sensitivity_array):\n",
    "        depth = sensitivity_array.shape[0]\n",
    "        # 确定扩展后sensitivity map的大小\n",
    "        # 计算stride为1时sensitivity map的大小\n",
    "        expanded_width = (self.input_width - self.filter_width + 2 * self.zero_padding + 1)\n",
    "        expanded_height = (self.input_height - self.filter_height + 2 * self.zero_padding + 1)\n",
    "        # 构建新的sensitivity_map\n",
    "        expand_array = np.zeros((depth, expanded_height, expanded_width))\n",
    "        # 从原始sensitivity map拷贝误差值\n",
    "        for i in range(self.output_height):\n",
    "            for j in range(self.output_width):\n",
    "                i_pos = i * self.stride\n",
    "                j_pos = j * self.stride\n",
    "                expand_array[:,i_pos,j_pos] = \\\n",
    "                    sensitivity_array[:,i,j]\n",
    "        return expand_array\n",
    "    \n",
    "    def create_delta_array(self):\n",
    "        return np.zeros((self.channel_number, self.input_height, self.input_width))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPoolingLayer(object):\n",
    "    def __init__(self, input_width, input_height, channel_number, \n",
    "                 filter_width, filter_height, stride):\n",
    "        self.input_width = input_width\n",
    "        self.input_height = input_height\n",
    "        self.channel_number = channel_number\n",
    "        self.filter_width = filter_width\n",
    "        self.filter_height = filter_height\n",
    "        self.stride = stride\n",
    "        \n",
    "        self.output_width = (input_width - filter_height) // stride + 1\n",
    "        self.output_height = (input_height - filter_height) // self.stride + 1\n",
    "        self.output_array = np.zeros((self.channel_number, self.output_height, self.output_width))\n",
    "    \n",
    "    def forward(self, input_array):\n",
    "        for d in range(self.channel_number):\n",
    "            for i in range(self.output_height):\n",
    "                for j in range(self.output_width):\n",
    "                    self.output_array[d,i,j] = (    \n",
    "                        get_patch(input_array[d], i, j,\n",
    "                            self.filter_width, \n",
    "                            self.filter_height, \n",
    "                            self.stride).max())\n",
    "    \n",
    "    def backward(self, input_array, sensitivity_array):\n",
    "        self.delta_array = np.zeros(input_array.shape)\n",
    "        for d in range(self.channel_number):\n",
    "            for i in range(self.output_height):\n",
    "                for j in range(self.output_width):\n",
    "                    patch_array = get_patch(\n",
    "                        input_array[d], i, j,\n",
    "                        self.filter_width, \n",
    "                        self.filter_height, \n",
    "                        self.stride)\n",
    "                    k, l = get_max_index(patch_array)\n",
    "                    self.delta_array[d, \n",
    "                        i * self.stride + k, \n",
    "                        j * self.stride + l] = \\\n",
    "                        sensitivity_array[d,i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "###测试前向传播和反向传播后跟新的filter结果是否正确\n",
    "def init_test():\n",
    "    a = np.array(\n",
    "        [[[0,1,1,0,2],\n",
    "          [2,2,2,2,1],\n",
    "          [1,0,0,2,0],\n",
    "          [0,1,1,0,0],\n",
    "          [1,2,0,0,2]],\n",
    "         [[1,0,2,2,0],\n",
    "          [0,0,0,2,0],\n",
    "          [1,2,1,2,1],\n",
    "          [1,0,0,0,0],\n",
    "          [1,2,1,1,1]],\n",
    "         [[2,1,2,0,0],\n",
    "          [1,0,0,1,0],\n",
    "          [0,2,1,0,1],\n",
    "          [0,1,2,2,2],\n",
    "          [2,1,0,0,1]]])\n",
    "    b = np.array(\n",
    "        [[[0,1,1],\n",
    "          [2,2,2],\n",
    "          [1,0,0]],\n",
    "         [[1,0,2],\n",
    "          [0,0,0],\n",
    "          [1,2,1]]])\n",
    "    cl = ConvLayer(5,5,3,3,3,2,1,2,IdentityActivator(),0.001)\n",
    "    cl.filters[0].weights = np.array(\n",
    "        [[[-1,1,0],\n",
    "          [0,1,0],\n",
    "          [0,1,1]],\n",
    "         [[-1,-1,0],\n",
    "          [0,0,0],\n",
    "          [0,-1,0]],\n",
    "         [[0,0,-1],\n",
    "          [0,1,0],\n",
    "          [1,-1,-1]]], dtype=np.float64)\n",
    "    cl.filters[0].bias=1\n",
    "    cl.filters[1].weights = np.array(\n",
    "        [[[1,1,-1],\n",
    "          [-1,-1,1],\n",
    "          [0,-1,1]],\n",
    "         [[0,1,0],\n",
    "         [-1,0,-1],\n",
    "          [-1,1,0]],\n",
    "         [[-1,0,0],\n",
    "          [-1,0,1],\n",
    "          [-1,0,0]]], dtype=np.float64)\n",
    "    return a, b, cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    a, b, cl = init_test()\n",
    "    cl.forward(a)\n",
    "    print (\"前向传播结果:\", cl.output_array)\n",
    "    cl.backward(a, b, IdentityActivator())\n",
    "    cl.update()\n",
    "    print (\"反向传播后更新得到的filter1:\",cl.filters[0])\n",
    "    print (\"反向传播后更新得到的filter2:\",cl.filters[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前向传播结果: [[[ 6.  7.  5.]\n",
      "  [ 3. -1. -1.]\n",
      "  [ 2. -1.  4.]]\n",
      "\n",
      " [[ 2. -5. -8.]\n",
      "  [ 1. -4. -4.]\n",
      "  [ 0. -5. -5.]]]\n",
      "=======================padded_array======================== [[[0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 1. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 2. 0. 2. 0. 2. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 2. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 0. 2. 0. 1. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0.]]]\n",
      "反向传播后更新得到的filter1: filter weights:\n",
      "array([[[-1.008,  0.99 , -0.009],\n",
      "        [-0.005,  0.994, -0.006],\n",
      "        [-0.006,  0.995,  0.996]],\n",
      "\n",
      "       [[-1.004, -1.001, -0.004],\n",
      "        [-0.01 , -0.009, -0.012],\n",
      "        [-0.002, -1.002, -0.002]],\n",
      "\n",
      "       [[-0.002, -0.002, -1.003],\n",
      "        [-0.005,  0.992, -0.005],\n",
      "        [ 0.993, -1.008, -1.007]]])\n",
      "bias:\n",
      "0.991\n",
      "反向传播后更新得到的filter2: filter weights:\n",
      "array([[[ 9.980e-01,  9.980e-01, -1.001e+00],\n",
      "        [-1.004e+00, -1.007e+00,  9.970e-01],\n",
      "        [-4.000e-03, -1.004e+00,  9.980e-01]],\n",
      "\n",
      "       [[ 0.000e+00,  9.990e-01,  0.000e+00],\n",
      "        [-1.009e+00, -5.000e-03, -1.004e+00],\n",
      "        [-1.004e+00,  1.000e+00,  0.000e+00]],\n",
      "\n",
      "       [[-1.004e+00, -6.000e-03, -5.000e-03],\n",
      "        [-1.002e+00, -5.000e-03,  9.980e-01],\n",
      "        [-1.002e+00, -1.000e-03,  0.000e+00]]])\n",
      "bias:\n",
      "-0.007\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0, 1, 1, 0, 2],\n",
       "         [2, 2, 2, 2, 1],\n",
       "         [1, 0, 0, 2, 0],\n",
       "         [0, 1, 1, 0, 0],\n",
       "         [1, 2, 0, 0, 2]],\n",
       " \n",
       "        [[1, 0, 2, 2, 0],\n",
       "         [0, 0, 0, 2, 0],\n",
       "         [1, 2, 1, 2, 1],\n",
       "         [1, 0, 0, 0, 0],\n",
       "         [1, 2, 1, 1, 1]],\n",
       " \n",
       "        [[2, 1, 2, 0, 0],\n",
       "         [1, 0, 0, 1, 0],\n",
       "         [0, 2, 1, 0, 1],\n",
       "         [0, 1, 2, 2, 2],\n",
       "         [2, 1, 0, 0, 1]]]), array([[[0, 1, 1],\n",
       "         [2, 2, 2],\n",
       "         [1, 0, 0]],\n",
       " \n",
       "        [[1, 0, 2],\n",
       "         [0, 0, 0],\n",
       "         [1, 2, 1]]]), <__main__.ConvLayer at 0x7f044a6095f8>)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_pool_test():\n",
    "    a = np.array(\n",
    "        [[[1,1,2,4],\n",
    "          [5,6,7,8],\n",
    "          [3,2,1,0],\n",
    "          [1,2,3,4]],\n",
    "         [[0,1,2,3],\n",
    "          [4,5,6,7],\n",
    "          [8,9,0,1],\n",
    "          [3,4,5,6]]], dtype=np.float64)\n",
    "\n",
    "    b = np.array(\n",
    "        [[[1,2],\n",
    "          [2,4]],\n",
    "         [[3,5],\n",
    "          [8,2]]], dtype=np.float64)\n",
    "\n",
    "    mpl = MaxPoolingLayer(4,4,2,2,2,2)\n",
    "    return a, b, mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pool():\n",
    "    a, b, mpl = init_pool_test()\n",
    "    mpl.forward(a)\n",
    "    print ('input array:\\n%s\\noutput array:\\n%s' % (a, mpl.output_array))\n",
    "    mpl.backward(a, b)\n",
    "    print ('input array:\\n%s\\nsensitivity array:\\n%s\\ndelta array:\\n%s' % (a, b, mpl.delta_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input array:\n",
      "[[[1. 1. 2. 4.]\n",
      "  [5. 6. 7. 8.]\n",
      "  [3. 2. 1. 0.]\n",
      "  [1. 2. 3. 4.]]\n",
      "\n",
      " [[0. 1. 2. 3.]\n",
      "  [4. 5. 6. 7.]\n",
      "  [8. 9. 0. 1.]\n",
      "  [3. 4. 5. 6.]]]\n",
      "output array:\n",
      "[[[6. 8.]\n",
      "  [3. 4.]]\n",
      "\n",
      " [[5. 7.]\n",
      "  [9. 6.]]]\n",
      "input array:\n",
      "[[[1. 1. 2. 4.]\n",
      "  [5. 6. 7. 8.]\n",
      "  [3. 2. 1. 0.]\n",
      "  [1. 2. 3. 4.]]\n",
      "\n",
      " [[0. 1. 2. 3.]\n",
      "  [4. 5. 6. 7.]\n",
      "  [8. 9. 0. 1.]\n",
      "  [3. 4. 5. 6.]]]\n",
      "sensitivity array:\n",
      "[[[1. 2.]\n",
      "  [2. 4.]]\n",
      "\n",
      " [[3. 5.]\n",
      "  [8. 2.]]]\n",
      "delta array:\n",
      "[[[0. 0. 0. 0.]\n",
      "  [0. 1. 0. 2.]\n",
      "  [2. 0. 0. 0.]\n",
      "  [0. 0. 0. 4.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 3. 0. 5.]\n",
      "  [0. 8. 0. 0.]\n",
      "  [0. 0. 0. 2.]]]\n"
     ]
    }
   ],
   "source": [
    "test_pool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_check():\n",
    "    '''\n",
    "    梯度检查\n",
    "    '''\n",
    "    # 设计一个误差函数，取所有节点输出项之和\n",
    "    error_function = lambda o: o.sum()\n",
    "    \n",
    "    # 计算forward值\n",
    "    a, b, cl = init_test()\n",
    "    cl.forward(a)\n",
    "    \n",
    "    # 求取sensitivity map\n",
    "    sensitivity_array = np.ones(cl.output_array.shape,\n",
    "                                dtype=np.float64)\n",
    "    # 计算梯度\n",
    "    cl.backward(a, sensitivity_array,\n",
    "                  IdentityActivator())\n",
    "    # 检查梯度\n",
    "    epsilon = 10e-4\n",
    "    for d in range(cl.filters[0].weights_grad.shape[0]):\n",
    "        for i in range(cl.filters[0].weights_grad.shape[1]):\n",
    "            for j in range(cl.filters[0].weights_grad.shape[2]):\n",
    "                cl.filters[0].weights[d,i,j] += epsilon\n",
    "                cl.forward(a)\n",
    "                err1 = error_function(cl.output_array)\n",
    "                cl.filters[0].weights[d,i,j] -= 2*epsilon\n",
    "                cl.forward(a)\n",
    "                err2 = error_function(cl.output_array)\n",
    "                expect_grad = (err1 - err2) / (2 * epsilon)\n",
    "                cl.filters[0].weights[d,i,j] += epsilon\n",
    "                print 'weights(%d,%d,%d): expected - actural %f - %f' % (\n",
    "                    d, i, j, expect_grad, cl.filters[0].weights_grad[d,i,j])\n",
    "\n",
    "\n",
    "def init_pool_test():\n",
    "    a = np.array(\n",
    "        [[[1,1,2,4],\n",
    "          [5,6,7,8],\n",
    "          [3,2,1,0],\n",
    "          [1,2,3,4]],\n",
    "         [[0,1,2,3],\n",
    "          [4,5,6,7],\n",
    "          [8,9,0,1],\n",
    "          [3,4,5,6]]], dtype=np.float64)\n",
    "\n",
    "    b = np.array(\n",
    "        [[[1,2],\n",
    "          [2,4]],\n",
    "         [[3,5],\n",
    "          [8,2]]], dtype=np.float64)\n",
    "\n",
    "    mpl = MaxPoolingLayer(4,4,2,2,2,2)\n",
    "\n",
    "    return a, b, mpl\n",
    "\n",
    "\n",
    "def test_pool():\n",
    "    a, b, mpl = init_pool_test()\n",
    "    mpl.forward(a)\n",
    "    print 'input array:\\n%s\\noutput array:\\n%s' % (a, mpl.output_array)\n",
    "    mpl.backward(a, b)\n",
    "    print 'input array:\\n%s\\nsensitivity array:\\n%s\\ndelta array:\\n%s' % (a, b, mpl.delta_array)\n",
    "\n",
    "\n",
    "def test_example():\n",
    "    a = np.array(\n",
    "        [[1,0,1,0],\n",
    "          [1,1,1,0],\n",
    "          [1,0,1,0],\n",
    "          [0,0,1,0]],\n",
    "          dtype=np.float64)\n",
    "    b = np.array(\n",
    "        [[[1,-1],\n",
    "          [1,-1]],\n",
    "         [[1,1],\n",
    "          [-1,-1]]], dtype=np.float64)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
